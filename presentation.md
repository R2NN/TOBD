# 📊 ПРЕЗЕНТАЦИЯ

## Enterprise Log Intelligence Platform
### Проектная работа по дисциплине «Технология обработки больших данных»

---

# Слайд 1: Титульный

## Enterprise Log Intelligence Platform
### Лог-анализ корпоративных систем

**Команда:** [Укажите состав]  
**Дисциплина:** Технология обработки больших данных  
**Дата:** 2025

---

# Слайд 2: Постановка задачи

## 🎯 Цель проекта

Разработать **распределённую систему** обработки данных, включающую:

- ✅ Инструменты для управления задачами
- ✅ Параллельную обработку больших объёмов данных
- ✅ Полный цикл работы с данными: **сбор → обработка → хранение → визуализация**

---

# Слайд 3: Технологический стек

## 🛠️ Используемые технологии

| Категория | Технология |
|-----------|------------|
| **Big Data** | Dask |
| **Orchestration** | Apache Airflow |
| **Storage** | PostgreSQL |
| **Backend** | FastAPI + Python |
| **ML/AI** | Sentence-BERT |
| **Monitoring** | Grafana + Prometheus |
| **Infrastructure** | Docker Compose |

---

# Слайд 4: Архитектура системы

## 🏗️ Общая архитектура

```
┌──────────────┐     ┌──────────────┐     ┌──────────────┐
│  Источник    │ ──▶ │   Airflow    │ ──▶ │  PostgreSQL  │
│   данных     │     │   ETL Flow   │     │  (RAW→DWH)   │
└──────────────┘     └──────────────┘     └──────────────┘
                            │
                            ▼
                     ┌──────────────┐
                     │    Dask      │
                     │  (parallel)  │
                     └──────────────┘
                            │
                            ▼
                     ┌──────────────┐
                     │   ML-анализ  │
                     │ Sentence-BERT│
                     └──────────────┘
                            │
                            ▼
                     ┌──────────────┐
                     │  Grafana +   │
                     │  Dashboard   │
                     └──────────────┘
```

---

# Слайд 5: ETL Pipeline

## 🔄 Extract → Transform → Load

### Extract
- ZIP-архивы, CSV, JSON
- Валидация данных
- Поиск базы знаний

### Transform (Dask)
- Параллельный парсинг логов
- ML-классификация
- Генерация эмбеддингов

### Load
- PostgreSQL (3 слоя данных)
- CSV/Excel отчёты
- API response

---

# Слайд 6: Параллельная обработка

## ⚡ Dask - Big Data технология

```python
# Параллельный парсинг файлов
@delayed
def process_file(filepath):
    return parse_logs(filepath)

# Выполнение на кластере
results = compute(*[process_file(f) for f in files])
```

**Производительность:**
| Файлов | Без Dask | С Dask |
|--------|----------|--------|
| 100 | ~50 сек | ~15 сек |
| 1000 | ~500 сек | ~130 сек |

---

# Слайд 7: Хранение данных

## 💾 PostgreSQL - 3 слоя данных

```
┌─────────────────────────────────────┐
│           RAW LAYER                 │
│  raw_logs - сырые данные            │
└─────────────────┬───────────────────┘
                  ▼
┌─────────────────────────────────────┐
│         STAGING LAYER               │
│  processed_logs - обработанные      │
└─────────────────┬───────────────────┘
                  ▼
┌─────────────────────────────────────┐
│           DWH LAYER                 │
│  analysis_results, incidents        │
└─────────────────────────────────────┘
```

---

# Слайд 8: ML-анализ

## 🧠 Интеллектуальная классификация

**Sentence-BERT модели:**
- `all-MiniLM-L6-v2` - лёгкая (быстрая)
- `Qwen3-Embedding-0.6B` - тяжёлая (точная)

**Процесс:**
1. Генерация эмбеддингов базы знаний
2. Классификация ERROR → Problem ID
3. Классификация WARNING → Anomaly ID
4. Связывание аномалий с проблемами
5. Вычисление Impact Score

---

# Слайд 9: Визуализация

## 📊 Grafana + Dashboard

**Grafana (6 дашбордов):**
- System Load
- ML Performance
- Errors & Anomalies
- FastAPI Metrics
- Logs Analysis
- Complete Overview

**FastAPI Dashboard:**
- KPI карточки
- Timeline Chart
- Time Machine
- Export (JSON, PDF, Excel)

---

# Слайд 10: Docker Compose

## 🐳 Развёртывание

```yaml
services:
  postgres:        # :5432 - хранение данных
  dask-scheduler:  # :8786/:8787 - параллелизм
  dask-worker:     # 2 реплики
  fastapi-app:     # :8001 - API + UI
  prometheus:      # :9090 - метрики
  grafana:         # :3000 - визуализация
```

**Запуск одной командой:**
```bash
docker-compose up -d
```

---

# Слайд 11: Структура проекта

## 📁 Организация кода

```
📁 bigdata_project/
 ┣ 📂 data/           # Исходные данные
 ┣ 📂 flows/          # ETL скрипты
 ┣ 📂 dask_jobs/      # Dask обработка
 ┣ 📂 grafana/        # Dashboards
 ┣ 📂 processing/     # ML-модули
 ┣ 📄 docker-compose.yml
 ┣ 📄 requirements.txt
 ┣ 📄 README.md
 ┗ 📄 report.md
```

---

# Слайд 12: Демонстрация

## 🎬 Live Demo

1. **Запуск системы:**
   ```bash
   docker-compose up -d
   ```

2. **Загрузка данных:**
   - Открыть http://localhost:8001
   - Загрузить ZIP с логами

3. **Просмотр результатов:**
   - FastAPI Dashboard: http://localhost:8001/dashboard
   - Grafana: http://localhost:3000
   - Dask: http://localhost:8787

---

# Слайд 13: Выполнение требований

## ✅ Соответствие ТЗ

| Требование | Статус | Реализация |
|------------|--------|------------|
| Big Data технология | ✅ | Dask |
| Система хранения | ✅ | PostgreSQL |
| ETL-процесс (3 задачи) | ✅ | Extract, Transform, Load |
| Визуализация | ✅ | Grafana (6 dashboards) |
| Docker Compose | ✅ | 6 сервисов |
| Документация | ✅ | README, ARCHITECTURE |

---

# Слайд 14: Результаты

## 🏆 Достигнутые результаты

- ✅ Полный **ETL-pipeline** с оркестрацией
- ✅ **Параллельная обработка** больших объёмов данных
- ✅ **PostgreSQL** хранилище с 3 слоями (RAW → DWH)
- ✅ **ML-классификация** ошибок и аномалий
- ✅ **Визуализация** в Grafana и веб-интерфейсе
- ✅ **Контейнеризация** через Docker Compose
- ✅ Полная **документация** архитектуры

---

# Слайд 15: Заключение

## 📌 Итоги

**Разработана распределённая система** обработки корпоративных логов:

🔹 **Dask** для параллельной обработки Big Data  
🔹 **PostgreSQL** для многослойного хранения  
🔹 **Airflow/ETL** для оркестрации задач  
🔹 **ML** для интеллектуальной классификации  
🔹 **Grafana** для визуализации метрик  
🔹 **Docker** для простого развёртывания  

---

# Спасибо за внимание!

## 🔗 Ссылки

- **GitHub:** [URL репозитория]
- **Демо:** http://localhost:8001

## ❓ Вопросы?

---

*Команда проекта, 2025*

